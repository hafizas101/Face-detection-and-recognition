{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import paths\n",
    "import face_recognition, cv2, os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Generate output directory\n",
    "result_dir = os.path.join(current_path, \"results\")\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)\n",
    "                          \n",
    "dataset_path = os.path.join(current_path, \"dataset\")\n",
    "faces_path = os.path.join(current_path, \"faces\")\n",
    "if not os.path.exists(faces_path):\n",
    "    os.mkdir(faces_path)\n",
    "input_video_path = os.path.join(current_path, \"input_video.mp4\")\n",
    "output_video_path = os.path.join(result_dir, \"output.mp4\")\n",
    "mod2_csv_path = os.path.join(result_dir, \"mod-et-emo-002.csv\")\n",
    "mod3_csv_path = os.path.join(result_dir, \"mod-et-emo-003.csv\")\n",
    "output_FPS = 2\n",
    "\n",
    "boundary_color = (0, 255, 0)   # (Blue, Green, Red)\n",
    "boundary_thickness = 2\n",
    "font_color = (0, 255, 0)       # (Blue, Green, Red)\n",
    "font_size = 0.8\n",
    "font_thickness = 2\n",
    "\n",
    "\"\"\"\n",
    "num is a very important variable. It controls how much frames per second of the video we are extracting so\n",
    "basically it is very computationally expensive and time consuming for long videos to perform frame by frame\n",
    "detection and processing. Hence we can periodically skip some frames. This is controlled by num variable. Setting\n",
    "num=1 would mean extract all frames. num = 2 means skip 1 frame and then extract the second and so on. num = 4\n",
    "would mean skip 3 frames and then extract 1 and then again skip 3 and so on.\n",
    "\"\"\"\n",
    "num = 2\n",
    "\n",
    "# Put the names of people which you want to recognize. The name must match the name of directory in dataset.\n",
    "names_to_recognize = [\"Rafa Nadal\"]\n",
    "\n",
    "\"\"\"\n",
    "This is an extremely important variable and 0.6 is its recommended value. The algorithm calculates distance between\n",
    "testing face embedding and all training face embeddings. If this distance is less than tolerance_threshold, match is\n",
    "considered True otherwise False. Hence increasing this value means embeddings with larger distances will also be True and hence, other males or women\n",
    "may also match (Flexible classifier). Decreasing this value means embeddings with lower distances will be True which means even\n",
    "Rafa would may also not find a match (Strict classifier). Play with it but 0.6 is recommended from official\n",
    "documentation and works fine here as well.\n",
    "\"\"\"\n",
    "tolerance_threshold = 0.6\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Thsis is the size of output faces. The main purpose of save same size of face even if images in training data\n",
    "different resolutions and size. It can be any value like 64, 128, 256. Same result.\n",
    "\"\"\"\n",
    "size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_frames_to_video(frames, output_FPS):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Be sure to use lower case\n",
    "    height, width, channels = frames[0].shape\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, output_FPS, (width, height))\n",
    "    for i, ff in enumerate (frames):\n",
    "        out.write(ff)\n",
    "    out.release\n",
    "    cv2.destroyAllWindows()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod-001 ==> Video Splitting in frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames Per Second: 25\n",
      "Total number of frames read: 61\n",
      "Time taken in reading the frames: 0.2550392150878906 seconds\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(input_video_path)\n",
    "FPS = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "print(\"Frames Per Second: \"+str(FPS))\n",
    "\n",
    "frames = []\n",
    "start = time.time()\n",
    "count = 0\n",
    "frame_originals = []\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    count = count + 1\n",
    "    if not ret:\n",
    "        break\n",
    "    if count % num == 0:        \n",
    "        frames.append(frame)\n",
    "#         cv2.imshow(\"Original\", frame)\n",
    "#         cv2.waitKey(0)\n",
    "end = time.time()\n",
    "print(\"Total number of frames read: \"+str(len(frames)))\n",
    "print(\"Time taken in reading the frames: {} seconds\".format(end-start))\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod-002 ==> Face detection per frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rafa Nadal is recognized in 5th frame.\n",
      "Rafa Nadal is recognized in 6th frame.\n",
      "Rafa Nadal is recognized in 7th frame.\n",
      "Rafa Nadal is recognized in 8th frame.\n",
      "Rafa Nadal is recognized in 9th frame.\n",
      "Rafa Nadal is recognized in 10th frame.\n",
      "Rafa Nadal is recognized in 11th frame.\n",
      "Rafa Nadal is recognized in 12th frame.\n",
      "Rafa Nadal is recognized in 13th frame.\n",
      "Rafa Nadal is recognized in 14th frame.\n",
      "Rafa Nadal is recognized in 15th frame.\n",
      "Rafa Nadal is recognized in 16th frame.\n",
      "Rafa Nadal is recognized in 17th frame.\n",
      "Rafa Nadal is recognized in 18th frame.\n",
      "Rafa Nadal is recognized in 19th frame.\n",
      "Rafa Nadal is recognized in 20th frame.\n",
      "Rafa Nadal is recognized in 21th frame.\n",
      "Rafa Nadal is recognized in 22th frame.\n",
      "Rafa Nadal is recognized in 28th frame.\n",
      "Rafa Nadal is recognized in 30th frame.\n",
      "Rafa Nadal is recognized in 31th frame.\n",
      "Rafa Nadal is recognized in 32th frame.\n",
      "Rafa Nadal is recognized in 33th frame.\n",
      "Rafa Nadal is recognized in 34th frame.\n",
      "Rafa Nadal is recognized in 35th frame.\n",
      "Rafa Nadal is recognized in 38th frame.\n",
      "Rafa Nadal is recognized in 39th frame.\n",
      "Rafa Nadal is recognized in 40th frame.\n",
      "Rafa Nadal is recognized in 41th frame.\n",
      "Rafa Nadal is recognized in 42th frame.\n",
      "Rafa Nadal is recognized in 60th frame.\n",
      "Rafa Nadal is recognized in 61th frame.\n",
      "Time taken in processing 61 frames: 10.152 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load some sample pictures and learn how to recognize them.\n",
    "\n",
    "imagePaths = list(paths.list_images(faces_path))\n",
    "sorted_paths = sorted(imagePaths)\n",
    "known_faces = []\n",
    "known_names = []\n",
    "\n",
    "for (i, imagePath) in enumerate(sorted_paths):\n",
    "    name = imagePath.split(os.path.sep)[-2]\n",
    "    face_img = face_recognition.load_image_file(imagePath)\n",
    "    e1 = face_recognition.face_encodings(face_img)\n",
    "    if len(e1)==1:\n",
    "        face_encoding = e1[0]    \n",
    "        known_faces.append(face_encoding)\n",
    "        known_names.append(name)\n",
    "        \n",
    "u = np.unique(np.asarray(known_names))\n",
    "u_list = u.tolist()\n",
    "count_trained_people = []\n",
    "for i, n in enumerate (u_list):\n",
    "    count_trained_people.append(known_names.count(n))\n",
    "    \n",
    "    \n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "frame_number = 0\n",
    "labelled = []\n",
    "frame_num = []\n",
    "person_code = []\n",
    "person_name = []\n",
    "Xs = []\n",
    "Ys = []\n",
    "Ws = []\n",
    "Hs = []\n",
    "scores = []\n",
    "count = np.zeros(len(names_to_recognize), dtype=int)\n",
    "start = time.time()\n",
    "\n",
    "for i, ff in enumerate(frames):\n",
    "    frame = ff.copy()\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "    # Find all the faces and face encodings in the current frame of video\n",
    "    face_locations = face_recognition.face_locations(rgb_frame, model=\"cnn\")\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "        \n",
    "    for cc, encoding in enumerate (face_encodings):\n",
    "        count_rep = np.zeros(len(names_to_recognize), dtype=int)\n",
    "        # See if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_faces, encoding, tolerance=tolerance_threshold)\n",
    "        dist = face_recognition.face_distance(known_faces, encoding)\n",
    "        \n",
    "        label = \"Unknown\"\n",
    "        top, right, bottom, left = face_locations[cc]\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), boundary_color, boundary_thickness)\n",
    "        name = None\n",
    "        \n",
    "        if True in matches:\n",
    "            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "            counts = {}\n",
    "\n",
    "            for l in matchedIdxs:            \n",
    "                name = known_names[l]\n",
    "                if name in names_to_recognize:\n",
    "                    idd = names_to_recognize.index(name)\n",
    "                    count_rep[idd] += 1 \n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "            name = max(counts, key=counts.get)\n",
    "\n",
    "#             k = names_to_recognize.index(name)\n",
    "#             s = count_rep[k]/count_trained_people[u_list.index(name)]\n",
    "#             if s > score_thresh:\n",
    "            \n",
    "        if name in names_to_recognize:\n",
    "            k = names_to_recognize.index(name)\n",
    "#             dd = (np.mean(1-dist))/(np.amax(1-dist))\n",
    "            dd = (dist - np.amin(dist))/(np.amax(dist) - np.amin(dist))\n",
    "            s = 1-np.mean(dd)\n",
    "#             print(matches)\n",
    "#             print(count_rep[k])\n",
    "#             print(np.max(dist) - np.mean(dist))\n",
    "#             print(s)\n",
    "            frame_num.append(i+1)\n",
    "            person_code.append(k)\n",
    "            person_name.append(name)\n",
    "            scores.append(s)\n",
    "            count[k] += 1\n",
    "            print(name+\" is recognized in \"+str(i+1)+\"th frame.\")\n",
    "            Xs.append(left)\n",
    "            Ys.append(top)\n",
    "            Ws.append(right-top)\n",
    "            Hs.append(bottom-top)\n",
    "            label = '%s (%.3f)' % (name, s)\n",
    "                \n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(frame, label, (left, y), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "    #             # show the output image\n",
    "#     cv2.imshow(\"Image\", frame)\n",
    "#     cv2.waitKey(0)\n",
    "    \n",
    "    labelled.append(frame)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Time taken in processing {0:1.0f} frames: {1:2.3f} seconds\".format(len(frames), end-start))\n",
    "cv2.destroyAllWindows()\n",
    "project2_dict = {'Frame': frame_num, 'X position': Xs, 'Y position': Ys, 'Width': Ws, 'Height': Hs,\n",
    "                 'Person code': person_code, 'Person name': person_name, 'Score': scores}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod-003 ==> Aggregation of person detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Person Code: 0\n",
      "Most Frequent Person appeared: Rafa Nadal\n",
      "Final result: 0.5125866077555127\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aggregated_person_code = np.argmax(count)\n",
    "print(\"Aggregated Person Code: \"+str(aggregated_person_code))\n",
    "aggregated_person_name = names_to_recognize[aggregated_person_code]\n",
    "print(\"Most Frequent Person appeared: \"+str(aggregated_person_name))\n",
    "num = len(scores)\n",
    "total_rep = 0\n",
    "total = 0\n",
    "for i in range (num):\n",
    "    total = total + scores[i]*count[person_code[i]]\n",
    "    total_rep = total_rep + count[person_code[i]]\n",
    "    \n",
    "final_code = total/total_rep\n",
    "print(\"Final result: \"+str(final_code))\n",
    "print(\"\\n\")\n",
    "\n",
    "project3_dict = {'Aggregated person code': aggregated_person_code, 'Aggregated person name': aggregated_person_name, 'Aggregated Score': final_code}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod-005 ==> Re-training of non-recognized faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing image 1/46\n",
      "[INFO] processing image 2/46\n",
      "[INFO] processing image 3/46\n",
      "[INFO] processing image 4/46\n",
      "This image is not suitable for training. Either more than 1 or no face has been detected here. Please delete this image from training data.\n",
      "Image path is: /home/arslan/Desktop/freelancer/15-face_recognition/face_rec1/face/dataset/Christiano Ronaldo/cris4.jpeg\n",
      "\n",
      "[INFO] processing image 5/46\n",
      "[INFO] processing image 6/46\n",
      "[INFO] processing image 7/46\n",
      "[INFO] processing image 8/46\n",
      "[INFO] processing image 9/46\n",
      "[INFO] processing image 10/46\n",
      "[INFO] processing image 11/46\n",
      "[INFO] processing image 12/46\n",
      "[INFO] processing image 13/46\n",
      "[INFO] processing image 14/46\n",
      "[INFO] processing image 15/46\n",
      "[INFO] processing image 16/46\n",
      "[INFO] processing image 17/46\n",
      "[INFO] processing image 18/46\n",
      "[INFO] processing image 19/46\n",
      "[INFO] processing image 20/46\n",
      "[INFO] processing image 21/46\n",
      "[INFO] processing image 22/46\n",
      "[INFO] processing image 23/46\n",
      "[INFO] processing image 24/46\n",
      "[INFO] processing image 25/46\n",
      "[INFO] processing image 26/46\n",
      "[INFO] processing image 27/46\n",
      "[INFO] processing image 28/46\n",
      "[INFO] processing image 29/46\n",
      "[INFO] processing image 30/46\n",
      "[INFO] processing image 31/46\n",
      "[INFO] processing image 32/46\n",
      "[INFO] processing image 33/46\n",
      "[INFO] processing image 34/46\n",
      "[INFO] processing image 35/46\n",
      "[INFO] processing image 36/46\n",
      "[INFO] processing image 37/46\n",
      "[INFO] processing image 38/46\n",
      "[INFO] processing image 39/46\n",
      "[INFO] processing image 40/46\n",
      "[INFO] processing image 41/46\n",
      "[INFO] processing image 42/46\n",
      "[INFO] processing image 43/46\n",
      "[INFO] processing image 44/46\n",
      "[INFO] processing image 45/46\n",
      "[INFO] processing image 46/46\n"
     ]
    }
   ],
   "source": [
    "imagePaths = list(paths.list_images(dataset_path))\n",
    "sorted_paths = sorted(imagePaths)\n",
    "\n",
    "\n",
    "for (i, imagePath) in enumerate(sorted_paths):\n",
    "    name = imagePath.split(os.path.sep)[-2]\n",
    "    output_img_folder = os.path.join(faces_path, str(name))\n",
    "    if not os.path.exists(output_img_folder):\n",
    "        os.mkdir(output_img_folder)\n",
    "    print(\"[INFO] processing image {}/{}\".format(i + 1,len(imagePaths)))\n",
    "    \n",
    "    img = cv2.imread(imagePath, 1)\n",
    "    rgb_frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    face_locations = face_recognition.face_locations(rgb_frame, model=\"cnn\")\n",
    "    if len(face_locations) != 1:\n",
    "        print(\"This image is not suitable for training. Either more than 1 or no face has been detected here. Please delete this image from training data.\")\n",
    "        print(\"Image path is: \"+str(imagePath)+\"\\n\")\n",
    "    else:\n",
    "        (top, right, bottom, left) = face_locations[0]\n",
    "        face = img [top:bottom, left:right]\n",
    "        face = cv2.resize(face, (size,size))\n",
    "#         cv2.imshow(\"Face\", face)\n",
    "#         cv2.waitKey(0)\n",
    "        output_img_path = os.path.join(output_img_folder, str(i+1)+\".jpg\")\n",
    "        cv2.imwrite(output_img_path, face)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod-006 ==> Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dir = os.path.join(result_dir, \"original_frames\")\n",
    "if not os.path.exists(frames_dir):\n",
    "    os.mkdir(frames_dir)\n",
    "\n",
    "labelled_dir = os.path.join(result_dir, \"labelled_frames\")\n",
    "if not os.path.exists(labelled_dir):\n",
    "    os.mkdir(labelled_dir)\n",
    "    \n",
    "for i, f in enumerate (frames):\n",
    "    file_name = os.path.join(frames_dir, str(i).zfill(5)+\".jpg\")\n",
    "    cv2.imwrite(file_name, f)\n",
    "    file_name = os.path.join(labelled_dir, str(i).zfill(5)+\".jpg\")\n",
    "    cv2.imwrite(file_name, labelled[i])\n",
    "\n",
    "# Save the video\n",
    "convert_frames_to_video(labelled, output_FPS)\n",
    " \n",
    "# Save CSV file\n",
    "if os.path.exists(mod2_csv_path):\n",
    "    os.remove(mod2_csv_path)\n",
    "df = pd.DataFrame(data=project2_dict)\n",
    "df.to_csv(mod2_csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "if os.path.exists(mod3_csv_path):\n",
    "    os.remove(mod3_csv_path)\n",
    "df = pd.DataFrame(data=project3_dict, index=[0])\n",
    "df.to_csv(mod3_csv_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
